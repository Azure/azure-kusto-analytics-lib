{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a simple classifier for predicting type of Iris & publish it in Kusto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open dataset from UCI Repository: __[Iris](http://archive.ics.uci.edu/ml/datasets/Iris)__\n",
    "\n",
    "The well known simple data set for classification. It contains 3 classes of 50 instances each, where each class refers to a type of iris plant. For each sample there are 4 attributes for Sepal & Petal Length & Width\n",
    " \n",
    "Predicted attribute: class of iris plant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import pickle\n",
    "import binascii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reload_ext Kqlmagic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving the table for classification from Kusto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%kql kusto://code;cluster='help';database='Samples'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: to make hash() consistent set env. variable PYTHONHASHSEED=0\n",
    "%env PYTHONHASHSEED=0\n",
    "\n",
    "q = '''\n",
    "Iris\n",
    "'''\n",
    "\n",
    "fn = \"df\" + str(hash(q)) + \".pkl\"\n",
    "print(\"Cache file name: \", fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = \"df\" + str(hash(q)) + \".pkl\"\n",
    "try:\n",
    "    df = pd.read_pickle(fn)\n",
    "    print(\"Load df from \" + fn)\n",
    "except:\n",
    "    print(\"Execute query...\")\n",
    "    try:\n",
    "        %kql res << -query q\n",
    "        df = res.to_dataframe()\n",
    "        print(\"Save df to \" + fn)\n",
    "        df.to_pickle(fn)\n",
    "        print(\"\\n\", df.shape, \"\\n\", df.columns)\n",
    "    except Exception as ex:\n",
    "        print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(df.shape, \"\\n\")\n",
    "print(df[-4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.groupby(['Species']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train[['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']]\n",
    "train_y = train['Species']\n",
    "test_x = test[['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']]\n",
    "test_y = test['Species']\n",
    "\n",
    "print(train_x.shape, train_y.shape, test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn import neighbors\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#four classifier types\n",
    "clf1 = tree.DecisionTreeClassifier()\n",
    "clf2 = LogisticRegression()\n",
    "clf3 = neighbors.KNeighborsClassifier()\n",
    "clf4 = naive_bayes.GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = clf1.fit(train_x, train_y)\n",
    "clf2 = clf2.fit(train_x, train_y)\n",
    "clf3 = clf3.fit(train_x, train_y)\n",
    "clf4 = clf4.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy on Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for clf, label in zip([clf1, clf2, clf3, clf4], ['Decision Tree', 'Logistic Regression', 'K Nearest Neighbour', 'Naive Bayes']):\n",
    "            scores = cross_val_score(clf, train_x, train_y, cv=5, scoring='accuracy')\n",
    "            print(\"Accuracy: %0.4f (+/- %0.4f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy on Testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for clf, label in zip([clf1, clf2, clf3, clf4], ['Decision Tree', 'Logistic Regression', 'K Nearest Neighbour', 'Naive Bayes']):\n",
    "            scores = cross_val_score(clf, test_x, test_y, cv=5, scoring='accuracy')\n",
    "            print(\"Accuracy: %0.4f (+/- %0.4f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the model to Kusto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_tbl = 'ML_Models'\n",
    "model_name = 'Iris'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a dataframe containing model name, timestamp & the serialized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmodel = pickle.dumps(clf4)\n",
    "smodel = binascii.hexlify(bmodel)\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "dfm = pd.DataFrame({'name':[model_name], 'timestamp':[now], 'model':[smodel]})\n",
    "dfm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store it in table of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "set_query = '''\n",
    ".set-or-append {0} <|\n",
    "let tbl = dfm;\n",
    "tbl\n",
    "'''.format(models_tbl)\n",
    "print(set_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%kql -query set_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract the last version of the named model from the table of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_query = '''\n",
    "let tbl_name = models_tbl;\n",
    "let m_name = model_name;\n",
    "table(tbl_name)\n",
    "| where name == m_name\n",
    "| top 1 by timestamp desc\n",
    "'''\n",
    "print(get_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%kql res << -query get_query\n",
    "model_df = res.to_dataframe()\n",
    "qmodel = model_df.loc[0, 'model']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the trained model object and test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import binascii\n",
    "\n",
    "bmodel = binascii.unhexlify(qmodel)\n",
    "clfp = pickle.loads(bmodel)\n",
    "print(clfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pscore = cross_val_score(clfp, test_x, test_y, cv=5, scoring='accuracy')\n",
    "print(\"Accuracy: %0.4f (+/- %0.4f)\" % (pscore.mean(), pscore.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfp.predict(test_x[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
